{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# End-to-End Learning | Practical Session Part I | Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym.wrappers\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from interfaces.expert import Policy\n",
    "from utils import make_Dirs\n",
    "import random\n",
    "\n",
    "ratio = [16, 10]\n",
    "plt.rcParams[\"figure.figsize\"] = ratio\n",
    "plt.rcParams.update({\"font.size\": 22})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hyperparameter\n",
    "The hyperparamter N_TIME is for setting the number of sampled state-action pairs for the data set D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_TIME = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories\n",
    "In the folder expert our sampled trajectories will be stored. The trajectory folder contains all created trajectories, which are saved as .gz archive files. In the reward folder the reward of the respective run can be tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make save directories\n",
    "SAVE_DIR = \"./expert/\"\n",
    "make_Dirs(SAVE_DIR)\n",
    "make_Dirs(SAVE_DIR + \"trajectory/\")\n",
    "make_Dirs(SAVE_DIR + \"reward/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Car Racing Environment\n",
    "![CarRacing](resources/Open_ai_gym.png)\n",
    "\n",
    "State consists of 96x96x3 pixels. Reward is -0.1 every frame and +1000/N for every track tile visited, where N is the total number of tiles in track.\n",
    "Some indicators are shown at the bottom of the window and the state RGB buffer. From left to right: true speed, four ABS sensors, steering wheel position, and gyroscope.\n",
    "Action space is three-dimensional: steer, gas and brake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# prepare environment and agent (expert)\n",
    "env = gym.make(\"CarRacing-v0\")\n",
    "env = gym.wrappers.Monitor(\n",
    "    env, SAVE_DIR + \"video/\", force=True, video_callable=lambda episode_id: True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Expert Interface\n",
    "We can use the 'left' and 'right' key on the keyboard for steering the vehicle. With 'A' we can accelerate and with 'S' we brake.\n",
    "With the following command we import our expert keyboard interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "policy = Policy(\"CarRacing-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there exists already some data in the expert folder, the summary csv file is loaded and the sampled trajectories will be appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    summary = pd.read_csv(SAVE_DIR + \"summary.csv\").values.tolist()\n",
    "except:\n",
    "    summary = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following main loop is for sampling the trajectories. In the beginning we wait 1 second as there are some frames invalid due to zooming.\n",
    "After that we are ready to start driving!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trajectory = []\n",
    "result = []\n",
    "observation = env.reset()\n",
    "action = policy.reset()\n",
    "\n",
    "while env.t <= 1.0:\n",
    "    env.render()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "print(\"Ready to start!\")\n",
    "\n",
    "\n",
    "# main loop to update trajectory\n",
    "for t_ in range(1, N_TIME + 1):\n",
    "    env.render()\n",
    "    action = policy(observation)\n",
    "    if \"Tensor\" in str(type(action)):\n",
    "        action = action.cpu().data.numpy().flatten()\n",
    "\n",
    "    trajectory.append(\n",
    "        (\n",
    "            np.asarray(observation, dtype=np.float32),\n",
    "            np.asarray(action, dtype=np.float32),\n",
    "        )\n",
    "    )\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    result.append(reward)\n",
    "\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "# close everything\n",
    "env.close()\n",
    "policy.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Saving\n",
    "After driving we need to save the sampled trajectory. We use pandas to generate GZ files with a corresponding unique file name.\n",
    "We append to the summary csv file the path of the trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record trajectory and return at the end of trajectory\n",
    "file_name = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "tmp = []\n",
    "print(\"Finish one episode, and record it to {}\".format(file_name))\n",
    "pd.to_pickle(trajectory, SAVE_DIR + \"trajectory/\" + file_name + \".gz\")\n",
    "tmp.append(SAVE_DIR + \"trajectory/\" + file_name + \".gz\")\n",
    "np.savetxt(\n",
    "    SAVE_DIR + \"reward/\" + file_name + \".csv\", np.array([result]).T, delimiter=\",\"\n",
    ")\n",
    "tmp.append(np.sum(result))\n",
    "print(tmp)\n",
    "summary.append(tmp)\n",
    "pd.DataFrame(summary, columns=[\"file\", \"return\"]).to_csv(\n",
    "    SAVE_DIR + \"summary.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of sampled trajectories: \", len(summary))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sampled_trajectories = pd.read_csv(SAVE_DIR + \"summary.csv\")[\"file\"].values.tolist()\n",
    "example_trajectorie = pd.DataFrame(pd.read_pickle(sampled_trajectories[-1]))\n",
    "\n",
    "state = example_trajectorie.iloc[:, 0].values.tolist()\n",
    "action = example_trajectorie.iloc[:, 1].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_rand = random.randint(1, len(state))\n",
    "plt.imshow(state[n_rand] / 255)\n",
    "plt.show()\n",
    "print(\n",
    "    \"The action performed at this time was \\nSteering {} \\nGas {} \\nBrake {}\".format(\n",
    "        action[n_rand][0], action[n_rand][1], action[n_rand][2]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Histogram of sampled actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "action_np = np.asarray(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Steering Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(action_np[:, 0], 20)\n",
    "plt.title(\"Histogram Steering Angle\")\n",
    "plt.xlabel(\"Steering Angle\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Throttle Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(action_np[:, 1], 20)\n",
    "plt.title(\"Histogram Throttle Position\")\n",
    "plt.xlabel(\"Throttle Position\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brake Pedal Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(action_np[:, 2], 20)\n",
    "plt.title(\"Histogram Brake Pedal Position\")\n",
    "plt.xlabel(\"Brake Pedal Position\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for reward in np.asarray(summary)[:, 1]:\n",
    "    rewards.append(float(reward))\n",
    "\n",
    "print(\n",
    "    \"statistics of total expert reward:\\n\\t max: {}\\t min: {}\"\n",
    "    \"\\n\\t median: {}\\t mean: {}\\t std: {}\".format(\n",
    "        np.max(rewards),\n",
    "        np.min(rewards),\n",
    "        np.median(rewards),\n",
    "        np.mean(rewards),\n",
    "        np.std(rewards),\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
